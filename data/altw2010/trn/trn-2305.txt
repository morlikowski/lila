In formula which is well formed and has a truth value. If the values of all variables in a propositional formula are given, it determines a unique truth value. A propositional formula may also be called a '''propositional expression''', a '''sentence''', or a '''sentential formula'''. 

A propositional formula is constructed from simple propositions, such as "''x'' is greater than three" or propositional variables such as ''P'' and ''Q'', using connectives such as NOT, AND, OR, and IMPLIES; for example:

:(''x'' = 2 AND ''y'' = 4) IMPLIES ''x'' + ''y'' = 6.

In mathematics, a propositional formula is often more briefly referred to as a "'''proposition'''", but, more precisely, a propositional formula is not a proposition but a formal expression that ''denotes'' a proposition, a formal object under discussion, just like an expression such as "" is not a value, but denotes a value. In some contexts, maintaining the distinction may be of importance.

==  Propositions ==
For the purposes of the propositional calculus, '''propositions''' (utterances, sentences, assertions) are considered to be either '''simple''' or '''compound'''.<ref> Hamilton 1978:1</ref> Compound propositions are considered to be linked by '''sentential connectives''', some of the most common of which are AND, OR, "IF ... THEN ...", "NEITHER ... NOR...", "... IS EQUIVALENT TO ..." . The linking semicolon " ; ", and connective BUT are considered to be expressions of AND. A sequence of discrete sentences are considered to be linked by ANDs, and formal analysis applies a recursive "parenthesis rule" with respect to sequences of simple propositions (see more below about well-formed formulas). 
: For example: The assertion: "This cow is blue. That horse is orange but this horse here is purple." is actually a compound proposition linked by ANDs: " ( ("This cow is blue" AND "that horse is orange") AND "this horse here is purple" ) ".
  
Simple propositions are declarative in nature, that is, they make assertions about the condition or nature of a ''particular'' object of sensation e.g. "This cow is blue", "There's a coyote!" ("That coyote IS ''there'', behind the rocks.").<ref>PM p. 91 eschews "the" because they require a clear-cut "object of sensation"; they stipulate the use of "this" (p. 91)</ref> Thus the simple "primitive" assertions must be about specific objects or specific states of mind. Each must have at least a '''subject''' (an immediate object of thought or observation), a verb (in the active voice and present tense preferred), and perhaps an adjective or adverb. "Dog!" probably implies "I see a dog" but should be rejected as too ambiguous.  

: Example: "That purple dog is running", "This cow is blue", "Switch M31 is closed", "This cap is off", "Tomorrow is Friday".    

For the purposes of the propositional calculus a compound proposition can usually be reworded into a series of simple sentences, although the result will probably sound stilted.

=== Relationship between propositional and predicate formulas ===
The predicate" form (where | symbolizes [[concatenation (stringing together) of symbols) into a form with the following blank-subject structure " ___|predicate," and the predicate in turn generalized to all things with that property.
: Example: "This blue pig has wings" becomes two sentences in the ''propositional calculus'': "This pig has wings" AND "This pig is blue." The first sentence breaks into "pig" as subject, and "has wings" as the predicate. Thus it asserts that object "pig" is a member of the class (set, collection) of "winged things". The second sentence asserts that object "pig" has an attribute "blue" and thus is a member of the class of "blue things". One might choose to write the two sentences connected with AND as:
:: p|W AND p|B

The generalization of "pig" to a (potential) member of two classes "winged things" and "blue things" means that it has a truth-relationship with both of these classes. In other words, given a '''domain of discourse''' "wingled things", either we find p to be a member of this domain or not. Thus we have a relationship W (wingedness) between p (pig) and { T, F }, W(p) evaluates to { T, F }. Likewise for B (blueness) and p (pig) and { T, F }: B(p) evaluates to { T, F }. So we now can analyze the connected assertions "B(p) AND W(p)" for its overall truth-value, i.e.: 
: ( B(p) AND W(p) ) evaluates to { T, F }  

In particular, simple sentences that employ notions of "all", "some", "a few", "one of", etc are treated by the predicate calculus. Along with the new function symbolism "F(x)" two new symbols are introduced: ∀ (For all), and ∃ (There exists ..., At least one of ... exists, etc.). The predicate calculus can handle the following statement:
: "All blue pigs have wings but some winged pigs are not blue".

=== Identity ===
Tarski asserts that the notion of IDENTITY (as distinguished from LOGICAL EQUIVALENCE) lies outside the propositional calculus; however, he notes that if a logic is to be of use for mathematics and the sciences it must contain a "theory" of IDENTITY.<ref>Tarski p.54-68. Suppes calls IDENTITY a "further rule of inference" and has a brief development around it; Robbin, Bender and Williamson, and Goodstein introduce the sign and its usage without comment or explanation. Hamilton p. 37 employs two signs ≠ and = with respect to the '''valuation''' of a formula in a formal calculus. Kleene p. 70 and Hamilton p. 52 place it in the predicate calculus, in particular with regards to the arithmetic of natural numbers.</ref> Some authors refer to "predicate logic with identity" to emphasize this extension. See more about this below.

== An algebra of propositions, the propositional calculus  ==
An '''algebra''' (and there are many different ones), loosely defined, is a method by which a collection of '''symbols''' called '''variables''' together with some other symbols such as parentheses (, ) and some sub-set of symbols such as *, +, ~, &, V, =, ≡, ⋀, ￢ are manipulated within a '''system''' of rules. These symbols, and '''well-formed''' strings of them, are said to represent '''objects''', but in a specific algebraic system these objects do not have '''meanings'''. Thus work inside the algebra becomes an exercise in obeying certain '''laws''' ('''rules''') of the algebra's syntax (symbol-formation) rather than in semantics (meaning) of the symbols. The meanings are to be found outside the algebra.

For a well-formed sequence of symbols in the algebra -- a '''formula''' -- to have some usefulness outside the algebra the symbols are assigned meanings and eventually the variables are assigned '''values'''; then by a series of rules the formula is '''evaluated'''.

When the values are restricted to just two and applied to the notion of '''simple sentences''' (e.g. spoken utterances or written assertions) linked by '''propositional connectives''' this whole algebraic system of symbols and rules and evaluation-methods is usually called the propositional calculus or the sentential calculus. 

While some of the familiar rules of arithmetic algebra continue to hold in the algebra of propositions (e.g. the commutative and associative laws for AND and OR), some do not (e.g. the distributive laws for AND, OR and NOT).

=== Usefulness of propositional formulas ===
'''Analysis''': In deductive reasoning, philosophers, rhetoricians and mathematicians reduce arguments to formulas and then study them (usually with truth tables) for correctness (soundness). For example: Is the following argument sound? 
: "Given that consciousness is sufficient for an artificial intelligence and only conscious entities can pass the Turing test, before we can conclude that a robot is an artificial intelligence the robot must pass the Turing test."
 
Engineers analyze the logic circuits they have designed using synthesis techniques and then apply various reduction and minimization techniques to simplify their designs.

'''Synthesis''': Engineers in particular synthesize propositional formulas (that eventually end up as '''circuits''' of symbols) from truth tables. For example, one might write down a truth table for how binary addition should behave given the addition of variables "b" and "a" and "carry_in" "ci", and the results "carry_out" "co" and "sum" Σ:
: Example: in row 5, ( (b+a) + ci ) = ( (1+0) + 1 ) = the number "2". written as a binary number this is 10<sub>2</sub>, where "co"=1 and Σ=0 as shown in the right-most columns.  
{| class="wikitable" style="text-align:center;"
|-
! row
! b !! a !! ci !! !! (b+a)+ci !! co !! Σ
|-
! 0
| 0 || 0 || 0 || || 0 || 0 || 0
|-
! 1
| 0 || 0 || 1 || || 1 || 0 || 1
|-
! 2
| 0 || 1 || 0 || || 1 || 0 || 1
|-
! 3
| 0 || 1 || 1 || || 2 || 1 || 0
|-
! 4
| 1 || 0 || 0 || || 1 || 0 || 1
|-
! 5
| 1 || 0 || 1 || || 2 || 1 || 0
|-
! 6
| 1 || 1 || 0 || || 2 || 1 || 0
|-
! 7
| 1 || 1 || 1 || || 3 || 1 || 1
|}

=== Propositional variables ===
The simplest type of propositional formula is a '''propositional variable'''. Propositions that are simple (atomic), symbolic expressions are often denoted by variables named ''a'', ''b'', or ''A'', ''B'', etc. A propositional variable is intended to represent an atomic proposition (assertion), such as "It is Saturday" = "a" (here the symbol = means " ... is assigned the variable named ...") or "I only go to the movies on Monday" = "b".

=== Truth-value assignments, formula evaluations ===
'''Evaluation''' of a propositional formula begins with assignment of a '''truth value''' to each variable. Because each variable represents a simple sentence, the truth values are being applied to the "truth" or "falsity" of these simple sentences.

'''Truth values in rhetoric, philosophy and mathematics''': The truth values are only two: { TRUTH "T",  FALSITY "F" }. An empiricist puts all propositions into two broad classes: ''analytic'' -- true no matter what (e.g. tautology), and ''synthetic'' -- derived from experience and thereby susceptible to confirmation by third parties (the verification theory of meaning)<ref>Empiricits eschew the notion of ''a priori'' (built-in, born-with) knowledge. "Radical reductionists" such as Locke and Hume "held that every idea must either originate directly in sense experience or else be compounded of ideas thus originating"; quoted from Quine reprinted in 1996 ''The Emergence of Logical Empriricism'', Garland Publishing Inc. http://www.marxists.org/reference/subject/philosophy/works/us/quine.htm </ref>. Empiricits hold that, in general, to arrive at the truth-value of a synthetic proposition, meanings (pattern-matching templates) must first be applied to the words, and then these meaning-templates must be matched against whatever it is that is being asserted. For example, my utterance "That cow is ''blue''!" Is this statement a TRUTH? Truly I said it. And maybe I ''am'' seeing a blue cow -- unless I am lying my statement is a TRUTH relative to the object of my (perhaps flawed) perception. But is the blue cow "really there"? What do you see when you look out the same window? In order to proceed with a verification, you will need a prior notion (a template) of both "cow" and "blue", and an ability to match the templates against the object of sensation (if indeed there is one).    

'''Truth values in engineering''': Engineers try to avoid notions of truth and falsity that bedevil philosophers, but in the final analysis engineers must trust their measuring instruments. In their quest for analog. Whenever decisions must be made in an analog system, quite often an engineer will convert an analog behavior (the door is 45.32146% UP) to digital (e.g. DOWN=0 ) by use of a comparator<ref>Neural net modelling offers a good mathematical model for a comparator as follows: Given a signal S and a threshold "thr", subtract "thr" from S and substitute this difference d to a sigmoid function: For large "gains" k, e.g. k=100, 1/( 1 + e<sup>-k*(d)</sup> ) = 1/( 1 + e<sup>-k*(S-thr)</sup> ) = { ≃0, ≃1 }. For example, if "The door is DOWN" means "The door is less than 50% of the way up", then a threshold thr=0.5 corresponding to 0.5*5.0 = +2.50 volts could be applied to a "linear" measuring-device with an output of 0 volts when fully closed and +5.0 volts when fully open.</ref>.   

Thus an assignment of '''meaning''' of the variables and the two value-symbols { 0 , 1 } comes from "outside" the formula that represents the behavior of the (usually) compound object. An example is a garage door with two "limit switches", one for UP labelled SW_U and one for DOWN labelled SW_D, and whatever else is in the door's circuitry. Inspection of the circuit (either the diagram or the actual objects themselves -- door, switches, wires, circuit board, etc) might reveal that, on the circuit board "node 22" goes to +0 volts when the contacts of switch "SW_D" are mechanically in contact ("closed") and the door is in the "down" position (95% down), and "node 29" goes to +0 volts when the door is 95% UP and the contacts of switch SW_U are in mechanical contact ("closed").<ref> In actuality the digital 1 and 0 are defined over non-overlapping ranges e.g. { "1" = +5/+0.2/-1.0 volts, 0 = +0.5/-0.2 volts }. When a value falls outside the defined range(s) the value becomes "u" -- unknown; e.g. +2.3 would be "u".</ref> The engineer must define the meanings of these voltages and all possible combinations (all 4 of them), including the "bad" ones (e.g. both nodes 22 and 29 at 0 volts, meaning that the door is open and closed at the same time). The circuit mindlessly responds to whatever voltages it experiences without any awareness of TRUTH or FALSEHOOD, RIGHT or WRONG, SAFE or DANGEROUS.

== Propositional connectives ==

Arbitrary propositional formulas are built from propositional variables and other propositional formulas using propositional connectives.  Examples of connectives include:
* The unary negation connective. If <math>\alpha</math> is a formula, then <math>\lnot \alpha</math> is a formula. 
* The classical binary connectives <math>\land, \lor, \to, \leftrightarrow</math>. Thus, for example, if <math>\alpha</math> and <math>\beta</math> are formulas, so is <math>(\alpha \to \beta)</math>. 
* Other binary connectives, such as NAND, NOR, and XOR
* The ternary connective IF ... THEN ... ELSE ...
* Constant 0-ary connectives ⊤ and ⊥ (alternately, constants { T, F }, { 1, 0 } etc. )
* The "theory-extension" connective EQUALS (alternately, IDENTITY, or the sign " = " as distinguished from the "logical connective" <math>\leftrightarrow</math>)

=== Connectives of rhetoric, philosophy and mathematics ===
The following are the connectives common to rhetoric, philosophy and mathematics together with their truth tables. The symbols used will vary from author to author and between fields of endeavor. In general the abbreviations "T" and "F" stand for the evaluations TRUTH and FALSITY applied to the variables in the propositional formula (e.g. the assertion: "That cow is blue" will have the truth-value "T" for Truth or "F" for Falsity, as the case may be.).

The connectives go by a number of different word-usages, e.g. "a IMPLIES b" is also said "IF a THEN b". Some of these are shown in the table. 

{|class="wikitable"
|- style="font-size:9pt" align="center" valign="bottom"
| width="48" Height="12" | 
| width="43.5" | 
| width="45" | 
| width="42" | 
| width="60" | 
| width="57.75" | 
|style="background-color:#E5E0EC" width="114.75" | b only if a
| width="187.5" | 
| width="93" | 
| width="87.75" | 
| width="48" | 
| width="63" | 

|- style="font-size:9pt" align="center"
| Height="12" | 
 | 
 | 
 | 
 | 
 | 
|style="background-color:#E5E0EC" | b IS SUFFICIENT FOR a
 | 
 | 
 | 
 | 
 | 

|- style="font-size:9pt" align="center"
| Height="12" | 
 | 
 | 
 | 
 | 
 | 
|style="background-color:#E5E0EC" | a IS NECESSARY FOR b
|style="background-color:#F2F2F2" | b IF AND ONLY IF a;  b IFF a
 | 
 | 
 | 
 | 

|- style="font-size:9pt" align="center"
| Height="12" | 
 | 
 | 
 | 
 | 
|style="background-color:#FDE9D9" | inclusive OR
|style="background-color:#E5E0EC" | IF b THEN a
|style="background-color:#F2F2F2" | b IS NECESSARY AND SUFFICENT FOR a
 | 
 | 
 | 
 | 

|- style="font-size:9pt" align="center"
| Height="12" | 
 | 
|style="background-color:#EAF1DD" | negation
|style="background-color:#EAF1DD" | negation
|style="background-color:#DBE5F1" | conjunction
|style="background-color:#FDE9D9" | disjunction
|style="background-color:#E5E0EC" | implication 
|style="background-color:#F2F2F2" | biconditional
 | 
 | 
 | 
 | 

|- style="font-size:9pt" align="center"
| Height="12" | variable
 | variable
|style="background-color:#EAF1DD" | NOT b
|style="background-color:#EAF1DD" | NOT a
|style="background-color:#DBE5F1" | b AND a
|style="background-color:#FDE9D9" | b OR a
|style="background-color:#E5E0EC" | b IMPLIES a
|style="background-color:#F2F2F2" | b IS LOGICALLY EQUIVALENT TO a ***
 | f IS A TAUTOLOGY
 | NEITHER a NOR b
 | b stroke a
 | exclusive OR

|- style="font-size:9pt" align="center"
|style="font-weight:bold" Height="12" | b
|style="font-weight:bold" | a
|style="background-color:#EAF1DD;font-weight:bold" | <math>\lnot</math>(b)
|style="background-color:#EAF1DD;font-weight:bold" | <math>\lnot</math>(a)
|style="background-color:#DBE5F1;font-weight:bold" | (b <math>\land</math> a)
|style="background-color:#FDE9D9;font-weight:bold" | (b <math>\lor</math> a)
|style="background-color:#E5E0EC;font-weight:bold" | (b <math>\to</math> a)
|style="background-color:#F2F2F2;font-weight:bold" | (b <math>\leftrightarrow</math> a)
 | (f = formula)
 | (a NOR b)
|style="font-weight:bold" | (b|a)
|style="font-weight:bold" | various

|-  align="center"
| Height="12" | F
 | F
|style="background-color:#EAF1DD" | T
|style="background-color:#EAF1DD" | T
|style="background-color:#DBE5F1" | F
|style="background-color:#FDE9D9" | F
|style="background-color:#E5E0EC;font-size:9pt" | T
|style="background-color:#F2F2F2;font-size:9pt" | T
|style="font-size:9pt" | T
|style="font-size:9pt" | T
 | T
|style="font-size:9pt" | F

|-  align="center"
| Height="12" | F
|style="font-size:9pt" | T
|style="background-color:#EAF1DD" | T
|style="background-color:#EAF1DD;font-size:9pt" | F
|style="background-color:#DBE5F1" | F
|style="background-color:#FDE9D9;font-size:9pt" | T
|style="background-color:#E5E0EC;font-size:9pt" | T
|style="background-color:#F2F2F2;font-size:9pt" | F
|style="font-size:9pt" | T
|style="font-size:9pt" | F
 | T
|style="font-size:9pt" | T

|-  align="center"
|style="font-size:9pt" Height="12" | T
 | F
|style="background-color:#EAF1DD" | F
|style="background-color:#EAF1DD" | T
|style="background-color:#DBE5F1" | F
|style="background-color:#FDE9D9;font-size:9pt" | T
|style="background-color:#E5E0EC;font-size:9pt" | F
|style="background-color:#F2F2F2;font-size:9pt" | F
|style="font-size:9pt" | T
|style="font-size:9pt" | F
 | T
|style="font-size:9pt" | T

|-  align="center"
|style="font-size:9pt" Height="12" | T
|style="font-size:9pt" | T
|style="background-color:#EAF1DD" | F
|style="background-color:#EAF1DD;font-size:9pt" | F
|style="background-color:#DBE5F1;font-size:9pt" | T
|style="background-color:#FDE9D9;font-size:9pt" | T
|style="background-color:#E5E0EC;font-size:9pt" | T
|style="background-color:#F2F2F2;font-size:9pt" | T
|style="font-size:9pt" | T
|style="font-size:9pt" | F
|style="font-size:9pt" | F
|style="font-size:9pt" | F

|}

=== Engineering connectives ===
500px|thumb|right| Engineering symbols have varied over the years, but these are commonplace. Sometimes they appear simply as boxes with symbols in them. "a" and "b" are called "the inputs" and "c" is called "the output". An output will typical "connect to" an input (unless it is the final connective); this accomplishes the mathematical notion of '''substitution'''.

In general, the engineering connectives are just the same as the mathematics connectives excepting they tend to evaluate with "1" = "T" and "0" = "F". This is done for the purposes of analysis/minimization and synthesis of formulas by use of the notion of ''minterms'' and Jevons' notion (a+a = a).<ref>While the notion of logical product is not so peculiar (e.g. 0*0=0, 0*1=0, 1*0=0, 1*1=1), the notion of (1+1=1 ''is'' peculiar; in fact (a "+" b) = (a + (b - a*b)) where "+" is the "logical sum" but + and - are the true arithmetic counterparts. Occasionally all four notions do appear in a formula: A AND B = 1/2*( A plus B minus ( A XOR B ) ] (cf p. 146 in John Wakerly 1978, ''Error Detecting Codes, Self-Checking Circuits and Applications, North-Holland, NY, ISBN 0-444-00259-6 pbk.)</ref> 

{|class="wikitable"
|- style="font-size:9pt" align="center" valign="bottom"
| width="57" Height="12" | 
| width="42" | 
| width="42" | 
| width="36.75" | 
| width="36.75" | 
| width="70.5" | logical product
| width="57.75" | logical sum
| width="42.75" | 
| width="43.5" | 
| width="93.75" | half-adder (no carry)

|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | 
 | 
 | 
 | 
 | 
 | 
 | 
 | 
 | 
 | exclusive OR

|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | row number
 | variable
 | variable
|style="background-color:#EAF1DD" | NOT
|style="background-color:#EAF1DD" | NOT
|style="background-color:#DBE5F1" | AND
|style="background-color:#FDE9D9" | OR
 | NAND
 | NOR
 | XOR

|-  align="center" valign="bottom"
|style="font-size:9pt" Height="12" | b*2<sup>1</sup>+a*2<sup>0</sup>
|style="font-size:9pt;font-weight:bold" | b
|style="font-size:9pt;font-weight:bold" | a
|style="background-color:#EAF1DD;font-size:9pt;font-weight:bold" | ~(b)
|style="background-color:#EAF1DD;font-size:9pt;font-weight:bold" | ~(a)
|style="background-color:#DBE5F1;font-size:9pt;font-weight:bold" | (b & a)
|style="background-color:#FDE9D9;font-size:9pt;font-weight:bold" | (b V a)
|style="font-size:9pt;font-weight:bold" | ~(b & a)
|style="font-size:9pt;font-weight:bold" | ~(b V a)
|style="font-size:14pt" | ⊕

|-  align="center" valign="bottom"
|style="font-size:9pt" Height="12" | 0
 | 0
 | 0
|style="background-color:#EAF1DD" | 1
|style="background-color:#EAF1DD" | 1
|style="background-color:#DBE5F1" | 0
|style="background-color:#FDE9D9" | 0
|style="font-size:9pt" | 1
|style="font-size:9pt" | 1
|style="font-size:9pt" | 0

|-  align="center" valign="bottom"
|style="font-size:9pt" Height="12" | 1
 | 0
|style="font-size:9pt" | 1
|style="background-color:#EAF1DD" | 1
|style="background-color:#EAF1DD;font-size:9pt" | 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#FDE9D9;font-size:9pt" | 1
|style="font-size:9pt" | 1
|style="font-size:9pt" | 0
|style="font-size:9pt" | 1

|-  align="center" valign="bottom"
|style="font-size:9pt" Height="12" | 2
|style="font-size:9pt" | 1
 | 0
|style="background-color:#EAF1DD" | 0
|style="background-color:#EAF1DD" | 1
|style="background-color:#DBE5F1" | 0
|style="background-color:#FDE9D9;font-size:9pt" | 1
|style="font-size:9pt" | 1
|style="font-size:9pt" | 0
|style="font-size:9pt" | 1

|-  align="center" valign="bottom"
|style="font-size:9pt" Height="12" | 3
|style="font-size:9pt" | 1
|style="font-size:9pt" | 1
|style="background-color:#EAF1DD" | 0
|style="background-color:#EAF1DD" | 0
|style="background-color:#DBE5F1;font-size:9pt" | 1
|style="background-color:#FDE9D9;font-size:9pt" | 1
|style="font-size:9pt" | 0
|style="font-size:9pt" | 0
|style="font-size:9pt" | 0

|}

=== CASE connective: IF ... THEN ... ELSE ... ===
The IF ... THEN ... ELSE ... connective appears as the simplest form of CASE operator of recursion theory and computation theory and is the connective responsible for conditional goto's (jumps, branches). From this one connective all other connectives can be constructed (see more below). Although " IF c THEN b ELSE a " sounds like an implication it is, in its most reduced form, a '''switch''' that makes a decision and offers as outcome only one of two alternatives "a" or "b" (hence the name switch statement in the C programming language). <ref>A careful look at its Karnaugh map shows that IF...THEN...ELSE can also be expressed, in a rather round-about way, in terms of two exclusive-ORs: ( (b AND (c XOR a)) OR (a AND (c XOR b)) ) = d.</ref>

The following three propositions are equivalent (as indicated by the logical equivalence sign ≡ ): 

:* (1) ( IF 'counter is zero' THEN 'go to instruction ''b'' ' ELSE 'go to instruction ''a'' ') ≡
:* (2) ( (c → b) & (~c → a) ) ≡  ( ( IF 'counter is zero' THEN 'go to instruction ''b'' ' ) AND ( IF 'It is NOT the case that counter is zero' THEN 'go to instruction ''a'' ) "  ≡
:* (3) ( (c & b) V (~c & a) ) =  " ( 'Counter is zero' AND 'go to instruction ''b'' ) OR ( 'It is NOT the case that 'counter is zero' AND 'go to instruction ''a'' ) "
 
Thus IF ... THEN ... ELSE -- unlike implication -- does not evaluate to an ambiguous "TRUTH" when the first proposition is false i.e. c = F in (c → b). For example, most people would reject the following compound proposition as a nonsensical ''non sequitor'' because the second sentence is ''not connected in meaning'' to the first.<ref>Robbin p. 3.</ref> 
: Example: The proposition " IF 'Winston Churchill was Chinese' THEN 'The sun rises in the east' " evaluates as a TRUTH given that 'Winston Church was Chinese' is a FALSEHOOD and 'The sun rises in the east' evaluates as a TRUTH. 

In recognition of this problem, the sign → of formal implication in the propositional calculus is called material implication to distinguish it from the everday, intuitive implication.<ref>Rosenbloom p. 30 and p. 54ff discusses this problem of implication at some length. Most philosophers and mathematicians just accept the material definition as given above. But some do not, including the intuitionists; they consider it a form of the law of excluded middle misapplied.</ref> 

The use of the IF ... THEN ... ELSE construction avoids controversy because it offers a completely deterministic choice between two stated alternatives; it offers two "objects" (the two alternatives b and a), and it ''selects'' between them exhaustively and unabiguously.<ref>Indeed, exhaustive selection between alternatives -- '''mutual exclusion''' -- is required by the definition that Kleene gives the CASE operator (Kleene 1952229)</ref>. In the truth table below, d1 is the formula: ( (IF c THEN b) AND (IF NOT-c THEN a) ). Its fully-reduced form d2 is the formula: ( (c AND b) OR (NOT-c AND a). The two formulas are equivalent as shown by the columns "=d1" and "=d2". Electrical engineers call the fully-reduced formula the AND-OR-SELECT operator. The CASE (or SWITCH) operator is an extension of the same idea to ''n'' possible, but mutually-exclusive outcomes. Electrical engineers call the CASE operator a multiplexer.
 
{|class="wikitable"
|- style="font-size:9pt" align="center"
| width="27.75" Height="12" | 
| width="20.25" | 
| width="18.75" | 
| width="18.75" | 
| width="6.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="16.5" | 
| width="12.75" | 
| width="12.75" | 
|style="background-color:#FDE9D9" width="17.25" | d1
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="18" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="24.75" | 
| width="5.25" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
|style="background-color:#FDE9D9" width="15.75" | d2
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="27" | 

|- style="font-size:9pt;font-weight:bold" align="center"
|style="background-color:#F2F2F2" Height="12" | row
 | c
 | b
 | a
|style="background-color:#A5A5A5" | 
 | (
 | (
 | c
 |  -->
 | b
 | )
|style="background-color:#FDE9D9" | &
 | (
|style="background-color:#EAF1DD" | ~
 | (
 | c
 | )
 |  -->
 | a
 | )
 | )
|style="background-color:#FDE9D9" |  =d1
|style="background-color:#A5A5A5" | 
 | (
 | (
 | c
|style="background-color:#DBEEF3" | &
 | b
 | )
|style="background-color:#FDE9D9" | V
 | (
|style="background-color:#EAF1DD" | ~
 | (
 | c
 | )
|style="background-color:#DBE5F1" | &
 | a
 | )
 | )
|style="background-color:#FDE9D9" |  =d2

|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 0
 | 0
 | 0
|style="background-color:#C5D9F1" | 0
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 0
 | 1
 | 0
 | 
|style="background-color:#B8CCE4" | 0
 | 
 | 1
 | 
 | 0
 | 
|style="background-color:#B8CCE4" | 0
|style="background-color:#B8CCE4" | 0
 | 
 | 
|style="background-color:#B8CCE4" | 0
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 0
 | 0
 | 0
 | 
|style="background-color:#B8CCE4" | 0
 | 
 | 1
 | 
 | 0
 | 
|style="background-color:#B8CCE4" | 0
|style="background-color:#B8CCE4" | 0
 | 
 | 
|style="background-color:#B8CCE4" | 0

|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 1
 | 0
 | 0
|style="background-color:#C5D9F1" | 1
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 0
 | 1
 | 0
 | 
|style="background-color:#B8CCE4" | 1
 | 
 | 1
 | 
 | 0
 | 
|style="background-color:#B8CCE4" | 1
|style="background-color:#B8CCE4" | 1
 | 
 | 
|style="background-color:#B8CCE4" | 1
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 0
 | 0
 | 0
 | 
|style="background-color:#B8CCE4" | 1
 | 
 | 1
 | 
 | 0
 | 
|style="background-color:#B8CCE4" | 1
|style="background-color:#B8CCE4" | 1
 | 
 | 
|style="background-color:#B8CCE4" | 1

|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 2
 | 0
 | 1
|style="background-color:#C5D9F1" | 0
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 0
 | 1
 | 1
 | 
|style="background-color:#B8CCE4" | 0
 | 
 | 1
 | 
 | 0
 | 
|style="background-color:#B8CCE4" | 0
|style="background-color:#B8CCE4" | 0
 | 
 | 
|style="background-color:#B8CCE4" | 0
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 0
 | 0
 | 1
 | 
|style="background-color:#B8CCE4" | 0
 | 
 | 1
 | 
 | 0
 | 
|style="background-color:#B8CCE4" | 0
|style="background-color:#B8CCE4" | 0
 | 
 | 
|style="background-color:#B8CCE4" | 0

|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 3
 | 0
 | 1
|style="background-color:#C5D9F1" | 1
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 0
 | 1
 | 1
 | 
|style="background-color:#B8CCE4" | 1
 | 
 | 1
 | 
 | 0
 | 
|style="background-color:#B8CCE4" | 1
|style="background-color:#B8CCE4" | 1
 | 
 | 
|style="background-color:#B8CCE4" | 1
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 0
 | 0
 | 1
 | 
|style="background-color:#B8CCE4" | 1
 | 
 | 1
 | 
 | 0
 | 
|style="background-color:#B8CCE4" | 1
|style="background-color:#B8CCE4" | 1
 | 
 | 
|style="background-color:#B8CCE4" | 1

|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 4
 | 1
|style="background-color:#DBEEF3" | 0
 | 0
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 1
|style="background-color:#DBEEF3" | 0
|style="background-color:#DBEEF3" | 0
 | 
|style="background-color:#DBEEF3" | 0
 | 
 | 0
 | 
 | 1
 | 
 | 1
 | 0
 | 
 | 
|style="background-color:#DBEEF3" | 0
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 1
|style="background-color:#DBEEF3" | 0
|style="background-color:#DBEEF3" | 0
 | 
|style="background-color:#DBEEF3" | 0
 | 
 | 0
 | 
 | 1
 | 
 | 0
 | 0
 | 
 | 
|style="background-color:#DBEEF3" | 0

|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 5
 | 1
|style="background-color:#DBEEF3" | 0
 | 1
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 1
|style="background-color:#DBEEF3" | 0
|style="background-color:#DBEEF3" | 0
 | 
|style="background-color:#DBEEF3" | 0
 | 
 | 0
 | 
 | 1
 | 
 | 1
 | 1
 | 
 | 
|style="background-color:#DBEEF3" | 0
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 1
|style="background-color:#DBEEF3" | 0
|style="background-color:#DBEEF3" | 0
 | 
|style="background-color:#DBEEF3" | 0
 | 
 | 0
 | 
 | 1
 | 
 | 0
 | 1
 | 
 | 
|style="background-color:#DBEEF3" | 0

|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 6
 | 1
|style="background-color:#DBEEF3" | 1
 | 0
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 1
|style="background-color:#DBEEF3" | 1
|style="background-color:#DBEEF3" | 1
 | 
|style="background-color:#DBEEF3" | 1
 | 
 | 0
 | 
 | 1
 | 
 | 1
 | 0
 | 
 | 
|style="background-color:#DBEEF3" | 1
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 1
|style="background-color:#DBEEF3" | 1
|style="background-color:#DBEEF3" | 1
 | 
|style="background-color:#DBEEF3" | 1
 | 
 | 0
 | 
 | 1
 | 
 | 0
 | 0
 | 
 | 
|style="background-color:#DBEEF3" | 1

|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 7
 | 1
|style="background-color:#DBEEF3" | 1
 | 1
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 1
|style="background-color:#DBEEF3" | 1
|style="background-color:#DBEEF3" | 1
 | 
|style="background-color:#DBEEF3" | 1
 | 
 | 0
 | 
 | 1
 | 
 | 1
 | 1
 | 
 | 
|style="background-color:#DBEEF3" | 1
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 1
|style="background-color:#DBEEF3" | 1
|style="background-color:#DBEEF3" | 1
 | 
|style="background-color:#DBEEF3" | 1
 | 
 | 0
 | 
 | 1
 | 
 | 0
 | 1
 | 
 | 
|style="background-color:#DBEEF3" | 1

|}

=== IDENTITY and evaluation ===

The first table of this section stars *** the entry LOGICAL EQUIVALENCE to note the fact that "Logical equivalence" is not the same thing as "identity". For example, most would agree that the assertion "That cow is blue" is identical to the assertion "That cow is blue". On the other hand ''logical'' equivalence sometimes appears in speech as in this example: " 'The sun is shining' means 'I'm biking' " Translated into a propositional formula the words become: "IF 'the sun is shining' THEN 'I'm biking', AND IF 'I'm biking' THEN 'the sun is shining'"<ref>The use of quote marks around the expressions is not accidental. Tarski comments on the use of quotes in his "18. Identity of things and identity of their designations; use of quotation marks" p. 58ff.</ref>.:
: "IF 's' THEN 'b' AND IF 'b' THEN 's' " is written as ((s → b) & (b → s)) or in an abbreviated form as (s ↔ b). As the rightmost symbol string is a '''definition''' for a new symbol in terms of the symbols on the left, the use of the IDENTITY sign = is appropriate:
:: ((s → b) & (b → s)) = (s ↔ b) 

Different authors use different signs for logical equivalence: ↔ (e.g. Suppes, Goodstein, Hamilton), ≡ (e.g. Robbin), ⇔ (e.g. Bender and Williamson). Typically identity is written as the equals sign =. One exception to this rule is found in ''Principia Mathematica''. For more about the philosophy of the notion of IDENTITY see Leibniz's law.  

As noted above, Tarski considers IDENTITY to lie outside the propositional calculus, but he asserts that without the notion, "logic" is insufficient for mathematics and the deductive sciences. In fact the sign comes into the propositional calculus when a formula is to be evaluated.<ref>Hamilton p. 37. Bender and Williamson p. 29 state "In what follows, we'll replace "equals" with the symbol " ⇔ " (equivalence) which is usually used in logic. We use the more familiar " = " for assigning meaning and values."</ref> 

In some systems there are no truth tables, but rather just formal axioms (e.g. strings of symbols from a set { ~, →, (, ), variables p<sub>1</sub>, p<sub>2</sub>, p<sub>3</sub>, ... } and formula-formation rules (rules about how to make more symbol strings from previous strings by use of e.g. substitution and modus ponens). the result of such a calculus will be another formula (i.e. a well-formed symbol string). Eventually, however, if one wants to use the calculus to study notions of validity and truth, one must add axioms that define the behavior of the symbols called "the truth values" {T, F} ( or {1, 0}, etc) relative to the other symbols. 

For example, Hamilton uses two symbols = and ≠ when he defines the notion of a '''valuation v''' of any wffs ''A'' and ''B'' in his "formal statement calculus" L. A valuation '''v''' is a ''function'' from the wffs of his system L to the range (output) { T, F }, given that each variable  p<sub>1</sub>, p<sub>2</sub>, p<sub>3</sub> in a wff is assigned an arbitrary truth value { T, F }.  
*(i) '''v'''(''A'') ≠ '''v'''(~''A'')
*(ii) '''v'''(''A'' → ''B'') = F if and only if '''v'''(''A'') = T and '''v'''(''B'') = F 

The two definitions (i) and (ii) define the equivalent of the truth tables for the ~ (NOT) and → (IMPLICATION) connectives of his system. The first one derives F ≠ T and T ≠ F, in other words " '''v'''(''A'') does not '''mean''' '''v'''(~''A'')". Definition (ii) specifies the third row in the truth table, and the other three rows then come from an application of definition (i). In particular (ii) '''assigns''' the value F (or a meaning of "F") to the entire expression. The definitions also serve as formation rules that allow substitution of a value previously derived into a formula:
{|class="wikitable"
|- style="font-size:9pt" align="center"
| width="8.25" Height="12" | 
| width="25.5" | 
|style="background-color:#E5E0EC" width="50" | v(A→B)
| width="29.25" | 
| width="6.75" | 

|- style="font-size:9pt" align="center"
| Height="12" | (
 | v(A)
|style="background-color:#E5E0EC" |  →
 | v(B)
 | )

|- style="font-size:9pt" align="center"
| Height="12" | 
 | F
|style="background-color:#E5E0EC" | T
 | F
 | 

|- style="font-size:9pt" align="center"
| Height="12" | 
 | F
|style="background-color:#E5E0EC" | T
 | T
 | 

|- style="font-size:9pt" align="center"
| Height="12" | 
 | T
|style="background-color:#CCC0DA" | F
 | F
 | 

|- style="font-size:9pt" align="center"
| Height="12" | 
 | T
|style="background-color:#E5E0EC" | T
 | T
 | 

|}

Some formal systems specify these valuation axioms at the outset in the form of certain formulas such as the law of contradiction or laws of identity and nullity. The choice of which ones to use, together with laws such as commutation and distribution, is up to the system's designer as long as the set of axioms is '''complete''' (i.e. sufficient to form and to evaluate any well-formed formula created in the system).

== More complex formulas ==
As shown above, the CASE (IF c THEN b ELSE a ) connective is constructed either from the 2-argument connectives IF...THEN... and AND or from OR and AND and the 1-argument NOT. Connectives such as the n-argument AND (a & b & c & ... & n), OR (a V b V c V ... V n) are constructed from strings of two-argument AND and OR and written in abbreviated form without the parentheses. These, and other connectives as well, can then used as building blocks for yet further connectives. Rhetoricians, philosophers, and mathematicians use truth tables and the various theorems to analyze and simplify their formulas. 

Electrical engineering uses drawn symbols and connect them with lines that stand for the mathematicals act of '''substitution''' and '''replacement'''. They then verify their drawings with truth tables and simplify the expressions as shown below by use of Karnaugh maps or the theorems. In this way engineers have created a host of "combinatorial logic" (i.e. connectives without feedback) such as "decoders", "encoders", "mutifunction gates", "majority logic", "binary adders", "arithmetic logic units", etc.

=== Definitions ===
A definition creates a new symbol and its behavior, often for the purposes of abbreviation. Once the definition is presented, either form of the equivalent symbol or formula can be used. The following symbolism =<sub>Df</sub> is following the convention of Reichenbach<ref>Reichenbach p. 20-22 and follows the conventions of PM. The symbol =<sub>Df</sub> is in the metalanguage and is not a formal symbol with the following meaning: "by symbol ' s ' is to have the same meaning as the formula '(c & d)' ".</ref>. Some examples of convenient definitions drawn from the symbol set { ~, &, (, ) } and variables. Each definition is producing a logically-equivalent formula that can be used for substitution or replacement.
:* definition of a new variable: (c & d) =<sub>Df</sub> s  
:* OR: ~(~a & ~b) =<sub>Df</sub> (a V b)
:* IMPLICATION: (~a V b) =<sub>Df</sub> (a → b)
:* XOR: (~a & b) V (a & ~b) =<sub>Df</sub> (a ⊕ b)
:* LOGICAL EQUIVALENCE: ( (a → b) & (b → a) ) =<sub>Df</sub> ( a ≡ b )

===Axiom and definition ''schemas'' ===
The definitions above for OR, IMPLICATION, XOR, and LOGICAL EQUIVALENCE are actually schemas (or "schemata"), that is, they are ''models'' (demonstrations, examples) for a general formula ''format'' but shown (for illustrative purposes) with specific letters a, b, c for the variables, whereas any variable letters can go in their places as long as the letter substitutions follow the rule of substitution below.
: Example: In the definition (~a V b) =<sub>Df</sub> (a → b), other variable-symbols such as "SW2" and "CON1" might be used, i.e. formally:
:: a =<sub>Df</sub> SW2, b =<sub>Df</sub> CON1, so we would have as an ''instance'' of the definition schema (~SW2 V CON1) =<sub>Df</sub> (SW2 → CON1)

=== Substitution versus replacement ===
'''Substitution''': The variable or sub-formula to be substituted with another variable, constant, or sub-formula must be replaced in all instances throughout the overall formula.
: Example: (c & d) V (p & ~(c & ~d)), but  (q1 & ~q2) ≡ d. Now wherever variable "d" occurs, substitute (q<sub>1</sub> & ~q<sub>2</sub>):
:: (c & (q<sub>1</sub> & ~q<sub>2</sub>)) V (p & ~(c & ~(q<sub>1</sub> & ~q<sub>2</sub>)))  

'''Replacement''': (i) the formula to be replaced must be within a tautology, i.e. ''logically equivalent'' ( connected by ≡ or ↔) to the formula that replaces it, and (ii) unlike substitution its permissible for the replacement to occur only in one place (i.e. for one formula).
:Example: Use this set of formula schemas/equivalences: 1: ( (a V 0) ≡ a ). 2: ( (a & ~a) ≡ 0 ). 3: ( (~a V b) =<sub>Df</sub> (a → b) ). 6. ( ~(~a) ≡ a )
:* start with "a": a 
:* Use 1 to replace "a" with (a V 0): (a V 0) 
:* Use the notion of "schema" to substitute b for a in 2: ( (a & ~a) ≡ 0 )
:* Use 2 to replace 0 with (b & ~b): ( a V (b & ~b) )
:* (see below for how to distribute "a V" over (b & ~b), etc

== Inductive definition ==

The classical presentation of propositional logic (see Enderton 2002) uses the connectives <math>\lnot, \land, \lor, \to, \leftrightarrow</math>. The set of formulas over a given set of propositional variables is inductively defined to be the smallest set of expressions such that:
* Each propositional variable in the set is a formula,
* <math>(\lnot \alpha)</math> is a formula whenever <math>\alpha</math> is, and 
*<math> (\alpha\,\Box\,\beta)</math> is a formula whenever <math>\alpha</math> and <math>\beta</math> are formulas and <math>\Box</math> is one of the binary connectives <math>\land, \lor, \to, \leftrightarrow</math>.
This inductive definition can be easily extended to cover additional connectives. 

The inductive definition can also be rephrased in terms of a closure operation (Enderton 2002). Let ''V'' denote a set of propositional variables and let ''X<sub>V</sub>'' denote the set of all strings from an alphabet including symbols in ''V'', left and right parentheses, and all the logical connectives under consideration.  Each logical connective corresponds to a formula building operation, a function from ''XX<sub>V</sub>'' to ''XX<sub>V</sub>'':
* Given a string ''z'', the operation <math>\mathcal{E}_\lnot(z)</math> returns <math>(\lnot z)</math>.
* Given strings ''y'' and ''z'', the operation <math>\mathcal{E}_\land(y,z)</math> returns <math>(y\land x)</math>. There are similar operations <math>\mathcal{E}_\lor</math>, <math>\mathcal{E}_\to</math>, and <math>\mathcal{E}_\leftrightarrow</math> corresponding to the other binary connectives.
The set of formulas over ''V'' is defined to be the smallest subset of ''XX<sub>V</sub>'' containing ''V'' and closed under all the formula building operations. 

== Parsing formulas ==
The following "laws" of the propositional calculus are used to "reduce" complex formulas. The "laws" can be easily verified with truth tables. For each law, the principal (outermost) connective is associated with logical equivalence ≡ or identity =. A complete analysis of all 2<sup>n</sup> combinations of truth-values for its n distinct variables will result in a column of 1's (T's) underneath this connective. This finding makes each law, by definition, a tautology. And, for a given law, because its formula on the left and right are equivalent (or identical) they can be substituted for one another.  
: Example: The following truth table is De Morgan's law for the behavior of NOT over OR: ~(a V b) ≡ (~a & ~b). To the left of the principal connective ≡ (yellow column labelled "taut") the formula ~(b V a) evaluates to (1, 0, 0, 0) under the label "P". On the right of "taut" the formula (~(b) V ~(a)) also evaluates to (1, 0, 0, 0) under the label "Q". As the two columns have equivalent evaluations, the logical equivalence ≡ under "taut" evaluates to (1, 1, 1, 1), i.e. P ≡ Q. Thus either formula can be substituted for the other if it appears in an larger formula.
{|class="wikitable"
|- style="font-size:9pt" align="center"
| width="18.75" Height="12" | 
| width="18.75" | 
| width="4.5" | 
| width="10.5" | 
|style="background-color:#D7E4BC" width="10.5" | P
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="11.25" | 
|style="background-color:#FFFF99" width="21.75" | taut
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="12" | 
|style="background-color:#DBE5F1" width="12.75" | Q
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 

|- style="font-weight:bold" align="center"
|style="font-size:9pt" Height="15" | b
|style="font-size:9pt" | a
|style="background-color:#A5A5A5;font-size:9pt" | 
|style="font-size:9pt" | (
|style="background-color:#D7E4BC;font-size:9pt" | ~
|style="font-size:9pt" | (
|style="font-size:9pt" | b
|style="background-color:#FDE9D9;font-size:9pt" | V
|style="font-size:9pt" | a
|style="font-size:9pt" | )
|style="background-color:#FFFF99" | ≡
|style="font-size:9pt" | (
|style="background-color:#EAF1DD;font-size:9pt" | ~
|style="font-size:9pt" | (
|style="font-size:9pt" | b
|style="font-size:9pt" | )
|style="background-color:#DBE5F1;font-size:9pt" | &
|style="background-color:#EAF1DD;font-size:9pt" | ~
|style="font-size:9pt" | (
|style="font-size:9pt" | a
|style="font-size:9pt" | )
|style="font-size:9pt" | )
|style="font-size:9pt" | )

|- style="font-size:9pt" align="center"
| Height="12" | 0
 | 0
|style="background-color:#A5A5A5" | 
 | 
|style="background-color:#D7E4BC" | 1
 | 
 | 0
|style="background-color:#FDE9D9" | 0
 | 0
 | 
|style="background-color:#FFFF99" | 1
 | 
|style="background-color:#EAF1DD" | 1
 | 
 | 0
 | 
|style="background-color:#DBE5F1" | 1
|style="background-color:#EAF1DD" | 1
 | 
 | 0
 | 
 | 
 | 

|- style="font-size:9pt" align="center"
| Height="12" | 0
 | 1
|style="background-color:#A5A5A5" | 
 | 
|style="background-color:#D7E4BC" | 0
 | 
 | 0
|style="background-color:#FDE9D9" | 1
 | 1
 | 
|style="background-color:#FFFF99" | 1
 | 
|style="background-color:#EAF1DD" | 1
 | 
 | 0
 | 
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 0
 | 
 | 1
 | 
 | 
 | 

|- style="font-size:9pt" align="center"
| Height="12" | 1
 | 0
|style="background-color:#A5A5A5" | 
 | 
|style="background-color:#D7E4BC" | 0
 | 
 | 1
|style="background-color:#FDE9D9" | 1
 | 0
 | 
|style="background-color:#FFFF99" | 1
 | 
|style="background-color:#EAF1DD" | 0
 | 
 | 1
 | 
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 1
 | 
 | 0
 | 
 | 
 | 

|- style="font-size:9pt" align="center"
| Height="12" | 1
 | 1
|style="background-color:#A5A5A5" | 
 | 
|style="background-color:#D7E4BC" | 0
 | 
 | 1
|style="background-color:#FDE9D9" | 1
 | 1
 | 
|style="background-color:#FFFF99" | 1
 | 
|style="background-color:#EAF1DD" | 0
 | 
 | 1
 | 
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 0
 | 
 | 1
 | 
 | 
 | 

|}

Enterprising readers might challenge themselves to invent an "axiomatic system" that uses the symbols { V, &, ~, (, ), variables a, b, c }, the formation rules specified above, as few as possible of the laws listed below, and then derive as theorems the others as well as the truth-table valuations for V, &, and ~. One set attributed to Huntington (1904) (Suppes:204) uses 8 of the laws defined below. 

Note that that if used in an axiomatic system, the symbols 1 and 0 (or T and F) are considered to be wffs and thus obey all the same rules as the variables. Thus the laws listed below are actually axiom schemas, that is, they stand in place of an infinite number of instances. Thus ( x V y ) ≡ ( y V x ) might be used in one instance, ( p V 0 ) ≡ ( 0 V p ) and in another instance ( 1 V q ) ≡ ( q V 1 ), etc. 

=== Connective seniority (symbol rank) ===
In general, to avoid confusion during analysis and evaluation of propositional formulas make liberal use parentheses. However, quite often authors leave them out. To parse a complicated fromula one first needs to know the '''seniority''', or '''rank''' that each of the connectives (excepting *) has over the other connectives. To" well-form" a formula start with the connective with the highest rank and add parentheses around its components, then move down in rank (paying close attention to the connective's '''socpe''' over which the it is working). From most- to least-senior, with the precidate signs ∀x and ∃x, the IDENTITY = and arithmetic signs added for completeness<ref>Rosenbloom 1950:32. Kleene 1952:73-74 ranks all 11 symbols.</ref>:
:: '''≡''' (LOGICAL EQUIVALENCE), '''→''' (IMPLICATION), '''&''' (AND), '''V''' (OR), '''~''' (NOT), '''∀x''' (FOR ALL x), '''∃x''' (THERE EXISTS AN x), '''=''' (IDENTITY), '''+''' (arithmetic sum), '''*'''(arithmetic multiply), ''' ' ''' (s, arithmetic successor).

Thus the formula can be parsed -- but note that, because NOT does not obey the distributive law, the parentheses around the inner formula (~c & ~d) is mandatory:
:Example: " d & c V w " rewritten is ( (d & c) V w )
:Example: " a & a → b ≡ a & ~a V b " rewritten (rigorously) is
::* ≡ has seniority: ( ( a & a → b ) ≡ ( a & ~a V b ) )
::* → has seniority: ( ( a & (a → b) ) ≡ ( a & ~a V b ) )
::* & has seniority both sides: ( ( ( (a) & (a → b) ) ) ≡ ( ( (a) & (~a V b) ) )
::* ~ has seniority: ( ( ( (a) & (a → b) ) ) ≡ ( ( (a) & (~(a) V b) ) )
::* check 9 ( -parenthesis and 9 ) -parenthesis: ( ( ( (a) & (a → b) ) ) ≡ ( ( (a) & (~(a) V b) ) ) 
:Example:
:: d & c V p & ~(c & ~d) ≡ c & d V p & c V p & ~d rewritten is ( ( (d & c) V ( p & ~((c & ~(d)) ) ) ) ≡ ( (c & d) V (p & c) V (p & ~(d)) ) )

=== Commutative and associative laws ===

Both AND and OR obey the commutative law and associative law:
* Commutative law for OR: ( a V b ) ≡ ( b V a )
* Commutative law for AND: ( a & b ) ≡ ( b & a )
* Associative law for OR: (( a V b ) V c ) ≡ ( a V (b V c) )
* Associative law for AND: (( a & b ) & c ) ≡ ( a & (b & c) )

'''Omitting parentheses in strings of AND and OR''': The connectives are considered to be unary (one-variable, e.g. NOT) and binary (i.e. two-variable AND, OR, IMPLIES). For example: 
:( (c & d) V (p & c) V (p & ~d) ) above should been written ( ((c & d) V (p & c)) V (p & ~(d) ) ) or possibly ( (c & d) V ( (p & c) V (p & ~(d)) ) )
However, a truth-table demonstration shows that the form without the extra parentheses is perfectly adequate.

'''Omitting parentheses with regards to a single-variable NOT''': While ~(a) where a is a single variable is perfectly clear, ~a is adequate and is the usual way this literal would appear. When the NOT is over a formula with more than one symbol, then the parentheses are mandatory, e.g. ~(a V b)

=== Distributive laws ===
OR distributes over AND and AND distributes over OR. NOT does not distribute over AND nor OR. See below about De Morgan's law:
* Distributive law for OR: ( c V ( a & b) ) ≡ ( (c V a) & (c V b) )
* Distributive law for AND: ( c & ( a V b) ) ≡ ( (c & a) V (c & b) )

=== De Morgan's laws ===
NOT, when distributed over OR or AND, does something peculiar (again, these can be verified with a truth-table):
* De Morgan's law for OR: ~(a V b) ≡ (~a & ~b)
* De Morgan's law for AND: ~(a & b) ≡ (~a V ~b)

=== Laws of absorption ===
Absorption, in particular the first one, cause the "laws" of logic to differ from the "laws" of arithmetic:
* Absorption (idempotency) for OR: (a V a) ≡ a
* Absorption (idempotency) for AND: (a & a) ≡ a

=== Laws of evaluation: Identity, nullity, and complement ===
The sign " = " (as distinguished from logical equivalence ≡, alternately ↔ or ⇔) symbolizes the assignment of value or meaning. Thus the string (a & ~(a)) symbolizes "1", i.e. it '''means''' the same thing as symbol "1" ". In some "systems" this will be an axiom (definition) perhaps shown as ( (a & ~(a)) =<sub>Df</sub> 1 ) ; in other systems, it may be derived in the truth table below: 
{|class="wikitable"
|- style="font-size:9pt" align="center"
| width="18.75" Height="12" | 
| width="4.5" | 
| width="9" | 
| width="9" | 
| width="10.5" | 
|style="background-color:#C5D9F1" width="10.5" | c
| width="9.75" | 
| width="9.75" | 
| width="15.75" | 
| width="8.25" | 
| width="8.25" | 
|style="background-color:#FFFF99" width="18" | taut
| width="13.5" | c
| width="11.25" | 

|- style="font-weight:bold" align="center"
|style="font-size:9pt" Height="15" | a
|style="font-size:9pt" | 
|style="font-size:9pt" | (
|style="font-size:9pt" | (
|style="font-size:9pt" | a
|style="background-color:#C5D9F1;font-size:9pt" | &
|style="background-color:#EAF1DD;font-size:9pt" | ~
|style="font-size:9pt" | (
|style="font-size:9pt" | a
|style="font-size:9pt" | )
|style="font-size:9pt" | )
|style="background-color:#FFFF99" | ≡
|style="font-size:9pt" | 0
|style="font-size:9pt" | )

|- style="font-size:9pt" align="center"
| Height="12" | 0
 | 
 | 
 | 
 | 0
|style="background-color:#C5D9F1" | 0
|style="background-color:#EAF1DD" | 1
 | 
 | 0
 | 
 | 
|style="background-color:#FFFF99" | 1
 | 0
 | 

|- style="font-size:9pt" align="center"
| Height="12" | 1
 | 
 | 
 | 
 | 1
|style="background-color:#C5D9F1" | 0
|style="background-color:#EAF1DD" | 0
 | 
 | 1
 | 
 | 
|style="background-color:#FFFF99" | 1
 | 0
 | 

|}

* Commutation of equality: (a = b) ≡ (b = a) 
* Identity for OR: (a V 0) = a or (a V F) = a
* Identity for AND: (a & 1) = a or (a & T) = a
* Nullity for OR: (a V 1) = 1  or (a V T) = T
* Nullity for AND: (a & 0) = 0  or (a & F) = F
* Complement for OR: (a V ~a) = 1 or (a V ~a) = T, law of excluded middle
* Complement for AND: (a & ~a) = 0 or (a & ~a) = F, law of contradiction

=== Double negative (Involution) ===
* ~(~a) = a

== Well-formed formulas (wffs) ==
A key property of formulas is that they can be uniquely parsed to determine the structure of the formula in terms of its propositional variables and logical connectives. When formulas are written in infix notation, as above, unique readability is ensured through an appropriate use of parentheses in the definition of formulas. Alternatively, formulas can be written in Polish notation or reverse Polish notation, eliminating the need for parentheses altogether. 

The inductive definition of infix formulas in the previous section can be converted to a formal grammar in Backus-Naur form:
:<code><formula> := <propositional variable></code>
:<code>| ( <math>\lnot</math> <formula> )</code>
:<code>| ( <formula> <math>\land</math> <formula>)</code>
:<code>| ( <formula> <math>\lor</math> <formula> )</code>
:<code>| ( <formula> <math>\to</math> <formula> )</code>
:<code>| ( <formula> <math>\leftrightarrow</math> <formula> )</code>

It can be shown that any expression matched by the grammar has a balanced number of left and right parentheses, and any nonempty initial segment of a formula has more left than right parentheses (Enderton 2002).<!-- I think he attributes this to someone else 
--> This fact can be used to give an algorithm for parsing formulas. For example, suppose that an expression ''x'' begins with <math>( \lnot</math>. Starting after the second symbol, match the shortest subexpression ''y'' of ''x'' that has balanced parentheses. If ''x'' is a formula, there is exactly one symbol left after this expression, this symbol is a closing parenthesis, and ''y'' itself is a formula. This idea can be used to generate a recursive descent parser for formulas.

'''Example of parenthesis counting''':

This method locates as "1" the '''principal connective''' -- the connective under which the overall evaluation of the formula occurs for the outer-most parentheses (which are often omitted)<ref>Robbin p. 7</ref>. It also locates the inner-most connective where one would begin evaluatation of the formula without the use of a truth table, e.g. at "level 6".
{|class="wikitable"
|- style="font-size:9pt" align="center" valign="bottom"
| width="32.25" Height="12" | 
| width="27.75" | start
|style="background-color:#99FF99" width="12" | (
|style="background-color:#99FF99" width="12" | (
|style="background-color:#99FF99" width="12" | (
| width="12" | c
| width="12" | &
| width="12" | d
|style="background-color:#FFC000" width="12" | )
| width="12" | V
|style="background-color:#99FF99" width="12" | (
| width="12" | p
| width="12" | &
| width="12" | ~
|style="background-color:#99FF99" width="12" | (
|style="background-color:#99FF99" width="12" | (
| width="12" | c
| width="12" | &
| width="12" | ~
|style="background-color:#99FF99" width="12" | (
| width="12" | d
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
| width="12" | =
|style="background-color:#99FF99" width="12" | (
|style="background-color:#99FF99" width="12" | (
|style="background-color:#99FF99" width="12" | (
| width="12" | c
| width="12" | &
| width="12" | d
|style="background-color:#FFC000" width="12" | )
| width="12" | V
|style="background-color:#99FF99" width="12" | (
| width="12" | p
| width="12" | &
| width="12" | d
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
| width="12" | V
|style="background-color:#99FF99" width="12" | (
| width="12" | p
| width="12" | &
| width="12" | ~
|style="background-color:#99FF99" width="12" | (
| width="12" | c
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )

|- style="font-size:9pt"
| Height="13.5" align="right" valign="bottom" | count
| align="center" valign="bottom" | 0
|style="background-color:#99FF99" align="center" valign="bottom" | 1
|style="background-color:#99FF99" align="center" valign="bottom" | 2
|style="background-color:#99FF99" align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
|style="background-color:#FFC000" align="center" valign="bottom" | 2
| align="center" valign="bottom" | 2
|style="background-color:#99FF99" align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
|style="background-color:#99FF99" align="center" valign="bottom" | 4
|style="background-color:#99FF99" align="center" valign="bottom" | 5
| align="center" valign="bottom" | 5
| align="center" valign="bottom" | 5
| align="center" valign="bottom" | 5
|style="background-color:#99FF99;font-weight:bold" align="center" valign="bottom" | 6
| align="center" valign="bottom" | 6
|style="background-color:#FFC000" align="center" valign="bottom" | 5
|style="background-color:#FFC000" align="center" valign="bottom" | 4
|style="background-color:#FFC000" align="center" valign="bottom" | 3
|style="background-color:#FFC000" align="center" valign="bottom" | 3
|style="background-color:#FFC000" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 1
|style="background-color:#99FF99" align="center" valign="bottom" | 2
|style="background-color:#99FF99" align="center" valign="bottom" | 3
|style="background-color:#99FF99" align="center" valign="bottom" | 4
| align="center" valign="bottom" | 4
| align="center" valign="bottom" | 4
| align="center" valign="bottom" | 4
|style="background-color:#FFC000" align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
|style="background-color:#99FF99" align="center" valign="bottom" | 4
| align="center" valign="bottom" | 4
| align="center" valign="bottom" | 4
| align="center" valign="bottom" | 4
|style="background-color:#FFC000" align="center" valign="bottom" | 3
|style="background-color:#FFC000" align="center" valign="bottom" | 2
| align="center" valign="bottom" | 2
|style="background-color:#99FF99" align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
|style="background-color:#99FF99" align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
|style="background-color:#FFC000" align="center" valign="bottom" | 3
|style="background-color:#FFC000" align="center" valign="bottom" | 2
|style="background-color:#FFC000" align="center" valign="bottom" | 1
|style="background-color:#FFC000" align="center" valign="bottom" | 0

|}

=== Wffs versus valid formulas in inferences ===
The notion of '''valid argument''' is usually applied to inferences in arguments, but arguments reduce to propositional formulas and can be evaluated the same as any other propositional formula. Here a '''valid''' inference means: "The formula that represents the inference evaluates to "truth" beneath its principal connective, no matter what truth-values are assigned to its variables", i.e. the formula is a tautology.<ref>cf Reichenbach p. 68 for a more involved discussion: "If the inference is valid and the premises are true, the inference is called ''conclusive''. </ref>. 
Quite possibly a formula will be ''well-formed'' but not '''valid'''. Another way of saying this is: "Being well-formed is ''necessary'' for a formula to be valid but it is not ''sufficient''." The only way to find out if it is ''both'' well-formed ''and'' valid is to submit it to verification with a truth table or by use of the "laws":

:Example 1: What does one make of the following difficult-to-follow assertion? Is it valid? "If it's sunny, but if the frog is croaking then it's not sunny, then it's the same as saying that the frog isn't croaking." Convert this to a propositional formula as follows: 
:: " IF (a AND (IF b THEN NOT-a) THEN NOT-a" where " a " represents "its sunny" and " b " represents "the frog is croaking":
:: ( ( (a) & ( (b) → ~(a) ) ≡ ~(b) ) 
: This is well-formed, but is it ''valid''? In other words, when evaluated will this yield a tautology (all T) beneath the logical-equivalence symbol ≡ ? The answer is NO, it is not valid. However, if reconstructed as an ''implication'' then the argument ''is'' valid.
:"Saying it's sunny, but if the frog is croaking then it's not sunny, ''implies'' that the frog isn't croaking."
:: Other circumstances may be preventing the frog from croaking: perhaps a crane ate it.

:Example 2 (from Reichenbach via Bertrand Russell):
:: "If pigs have wings, some winged animals are good to eat. Some winged animals are good to eat, so pigs have wings."
:: ( ((a) → (b)) & (b) → (a) ) is well formed, but an invalid argument as shown by the red evaluation under the principal implication:
{|class="wikitable"
|- style="font-size:9pt" align="center"
| width="18.75" Height="12" | W
| width="18.75" | G
| width="4.5" | 
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="16.5" | 
| width="10.5" | 
| width="11.25" | 
| width="16.5" | 
| width="10.5" | 
| width="10.5" | 
|style="background-color:#CCC0DA" width="19.5" | arg
| width="14.25" | 
| width="12" | 

|- style="font-weight:bold" align="center"
|style="font-size:9pt" Height="12.75" | a
|style="font-size:9pt" | b
|style="font-size:9pt" | 
|style="font-size:9pt" | (
|style="font-size:9pt" | (
|style="font-size:9pt" | (
|style="font-size:9pt" | a
|style="background-color:#F2DDDC;font-size:9pt" |  -> 
|style="font-size:9pt" | b
|style="font-size:9pt" | )
|style="background-color:#DBE5F1" | &
|style="font-size:9pt" | b
|style="font-size:9pt" | )
|style="background-color:#CCC0DA;font-size:9pt" |  -> 
|style="font-size:9pt" | a
|style="font-size:9pt" | )

|- style="font-size:9pt" align="center"
| Height="12" | 0
 | 0
 | 
 | 
 | 
 | 
 | 0
|style="background-color:#F2DDDC" | 1
 | 0
 | 
|style="background-color:#DBE5F1" | 0
 | 0
 | 
|style="background-color:#CCC0DA" | 1
 | 0
 | 

|- style="font-size:9pt" align="center"
| Height="12" | 0
 | 1
 | 
 | 
 | 
 | 
 | 0
|style="background-color:#F2DDDC" | 1
 | 1
 | 
|style="background-color:#DBE5F1" | 1
 | 1
 | 
|style="background-color:#FF0000" | 0
 | 0
 | 

|- style="font-size:9pt" align="center"
| Height="12" | 1
 | 0
 | 
 | 
 | 
 | 
 | 1
|style="background-color:#F2DDDC" | 0
 | 0
 | 
|style="background-color:#DBE5F1" | 0
 | 0
 | 
|style="background-color:#CCC0DA" | 1
 | 1
 | 

|- style="font-size:9pt" align="center"
| Height="12" | 1
 | 1
 | 
 | 
 | 
 | 
 | 1
|style="background-color:#F2DDDC" | 1
 | 1
 | 
|style="background-color:#DBE5F1" | 1
 | 1
 | 
|style="background-color:#CCC0DA" | 1
 | 1
 | 

|}

== Reduced sets of connectives ==

400px|thumb|right|The engineering symbol for the NAND connective (the 'stroke') can be used to build any propositional formula. The notion that truth (1) and falsity (0) can be defined in terms of this connective is shown in the sequence of NANDs on the left, and the derivations of the four evaluations of a NAND b are shown along the bottom. The more common method is to use the definition of the NAND from the truth table.

A set of logical connectives is called '''complete''' if every propositional formula is tautologically equivalent to a formula with just the connectives in that set. There are many complete sets of connectives, including <math>\{\land, \lnot\}</math>, <math>\{\lor, \lnot\}</math>, and <math>\{\to, \lnot\}</math>. There are two binary connectives that are complete on their own, corresponding to NAND and NOR, respectively.<ref>As well as the first three, Hamilton pp.19-22 discusses logics built from only | (NAND), and ↓ (NOR).</ref> Some pairs are not complete, for example <math>\{\land, \lor\}</math>.
=== The stroke (NAND) ===
The binary connective corresponding to NAND is called the Sheffer stroke, and written with a vertical bar | or vertical arrow ↑. The completeness of this connective was noted in ''Principia Mathematica'' (1927:xvii). Since it is complete on its own, all other connectives can be expressed using only the stroke. For example, where the symbol " ≡ " represents ''logical equivalence'':
: ~p ≡ p|p
: p → q ≡ p|~q
: p V q ≡ ~p|~q
: p & q ≡ ~(p|q) 
In particular, the zero-ary connectives <math>\top</math> (representing truth) and <math>\bot</math> (representing falsity) can be expressed using the stroke:
:<math>\top \equiv (a|(a|a))</math>
:<math>\bot \equiv (\top | \top)</math>

=== IF ... THEN ... ELSE ===

This connective together with { 0, 1 }, ( or { F, T } or { <math>\bot</math>, <math>\top</math> } ) forms a complete set. In the following the IF...THEN...ELSE relation (c, b, a) = d represents ( (c → b) V (~c → b) ) ≡ ( (c & b) V (~c & a) ) = d
: (c, b, a):
: (c, 0, 1) ≡ ~c
: (c, b, 1) ≡ (c → b)
: (c, c, a) ≡ (c V a) 
: (c, b, c) ≡ (c & b)

Example: The following shows how a theorem-based proof of "(c, b, 1) ≡ (c → b)" would proceed, below the proof is its truth-table verification. ( Note: (c → b) is ''defined'' to be (~c V b) ): 
:* Begin with the reduced form: ( (c & b) V (~c & a) )
:* Substitute "1" for a: ( (c & b) V (~c & 1) ) 
:* Identity (~c & 1) = ~c: ( (c & b) V (~c) )
:* Law of commutation for V:  ( (~c) V (c & b)  )
:* Distribute "~c V" over (c & b): ( ((~c) V c ) & ((~c) V b )
:* Law of excluded middle (((~c) V c ) = 1 ): ( (1) & ((~c) V b ) )
:* Distribute "(1) &" over ((~c) V b): ( ((1) & (~c)) V ((1) & b )) )
:* Commutivity and Identity (( 1 & ~c) = (~c & 1) = ~c, and (( 1 & b) ≡ (b & 1) ≡ b: ( ~c V b )
:* ( ~c V b ) is defined as '''c → b''' Q. E. D.

In the following truth table the column labelled "taut" for tautology evaluates '''logical equivalence''' (symbolized here by ≡) between the two columns labelled d. Because all four rows under "taut" are 1's, the equivalence indeed represents a tautology.
{|class="wikitable"
|- style="font-size:9pt" align="center"
| width="27.75" Height="12" | 
| width="20.25" | 
| width="18.75" | 
| width="18.75" | 
| width="6.75" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
|style="background-color:#FDE9D9" width="11.25" | d
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="12.75" | 
|style="background-color:#DDD9C3" width="19.5" | taut
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
|style="background-color:#FDE9D9" width="11.25" | d
| width="11.25" | 
| width="12.75" | 
| width="12.75" | 

|- style="font-size:9pt;font-weight:bold" align="center"
|style="background-color:#F2F2F2" Height="12" | rows
 | c
 | b
 | a
|style="background-color:#A5A5A5" | 
 | (
 | (
 | (
 | c
|style="background-color:#DBE5F1" | &
 | b
 | )
|style="background-color:#FDE9D9" | V
 | (
|style="background-color:#EAF1DD" | ~
 | (
 | c
 | )
|style="background-color:#DBE5F1" | &
 | a
 | )
 | )
|style="background-color:#DDD9C3" |  ≡
 | (
|style="background-color:#EAF1DD" | ~
 | (
 | c
 | )
|style="background-color:#FDE9D9" | V
 | b
 | )
 | )

|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 0,1
 | 0
 | 0
 | 1
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 
 | 0
|style="background-color:#DBE5F1" | 0
 | 0
 | 
|style="background-color:#FDE9D9" | 1
 | 
|style="background-color:#EAF1DD" | 1
 | 
 | 0
 | 
|style="background-color:#DBE5F1" | 1
 | 1
 | 
 | 
|style="background-color:#DDD9C3" | 1
 | 
|style="background-color:#EAF1DD" | 1
 | 
 | 0
 | 
|style="background-color:#FDE9D9" | 1
 | 0
 | 
 | 

|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 2,3
 | 0
 | 1
 | 1
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 
 | 0
|style="background-color:#DBE5F1" | 0
 | 1
 | 
|style="background-color:#FDE9D9" | 1
 | 
|style="background-color:#EAF1DD" | 1
 | 
 | 0
 | 
|style="background-color:#DBE5F1" | 1
 | 1
 | 
 | 
|style="background-color:#DDD9C3" | 1
 | 
|style="background-color:#EAF1DD" | 1
 | 
 | 0
 | 
|style="background-color:#FDE9D9" | 1
 | 1
 | 
 | 

|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 4,5
 | 1
 | 0
 | 1
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 
 | 1
|style="background-color:#DBE5F1" | 0
 | 0
 | 
|style="background-color:#FDE9D9" | 0
 | 
|style="background-color:#EAF1DD" | 0
 | 
 | 1
 | 
|style="background-color:#DBE5F1" | 0
 | 1
 | 
 | 
|style="background-color:#DDD9C3" | 1
 | 
|style="background-color:#EAF1DD" | 0
 | 
 | 1
 | 
|style="background-color:#FDE9D9" | 0
 | 0
 | 
 | 

|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 6,7
 | 1
 | 1
 | 1
|style="background-color:#A5A5A5" | 
 | 
 | 
 | 
 | 1
|style="background-color:#DBE5F1" | 1
 | 1
 | 
|style="background-color:#FDE9D9" | 1
 | 
|style="background-color:#EAF1DD" | 0
 | 
 | 1
 | 
|style="background-color:#DBE5F1" | 0
 | 1
 | 
 | 
|style="background-color:#DDD9C3" | 1
 | 
|style="background-color:#EAF1DD" | 0
 | 
 | 1
 | 
|style="background-color:#FDE9D9" | 1
 | 1
 | 
 | 

|}

== Normal forms ==

An arbitrary propositional formula may have a very complicated structure. It is often convenient to work with formulas that have simpler forms, known as '''normal forms'''. Some common normal forms include conjunctive normal form and disjunctive normal form. Any propositional formula can be reduced to its conjunctive or disjunctive normal form.

=== Reduction to normal form ===

'''Funkcja zdaniowa''' (inaczej '''predykat''' lub '''forma zdaniowa''') to wyrażenie językowe zawierające zmienne wolne, które w wyniku związania tych zmiennych kwantyfikatorami lub podstawienia za nie odpowiednich nazw staje się zdaniem.

Dla funkcji (formy) zdaniowej ''F(x)'' o jednej zmiennej wolnej x, rozważanej w zbiorze X, wprowadza się pojęcie '''dziedziny''' ''DX(F)'' lub ''D(F,X)'' funkcji zdaniowej, obejmując tą nazwą podzbiór elementów zbioru X o tej własności, że po podstawieniu w funkcji zdaniowej ''F(x)'' w miejsce zmiennej ''x'' nazw tych elementów otrzymuje się zdanie prawdziwe lub fałszywe.

Każde równanie liczbowe i każda taka nierówność z jedną niewiadomą jest funkcją (formą) zdaniową, której dziedziną jest pewien zbiór liczb. Każde równanie z dwiema lub więcej niewiadomymi jest funkcją  zdaniową, której dziedziną jest zbiór par lub trójek lub odpowiednio większej ilości liczb. Jeżeli zdanie ''F(a)'' jest prawdziwe, to mówi się, że element ''a'' '''spełnia''' funkcję zdaniową  ''F(x)''. Zbiór elementów zbioru X spełniających daną funkcję zdaniową nazywa się '''ekstensją funkcji zdaniowej''' lub '''wykresem formy zdaniowej''' w X.

==Przykład==
Funkcja zdaniowa ''x>2'' zamienia się w zdanie dla tych ''x'', dla których ten zapis ma sens. Wszelkie liczby rzeczywiste należą więc do jej dziedziny, podczas gdy na przykład nazwa SŁOŃ lub liczba zespolona ''1+2i'' już nie. Ekstensją natomiast jest podzbiór liczb rzeczywistych, które są większe od 2.